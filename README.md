# kubernetes-haproxy-autolb
k8s 使用多  Haproxy自动发现代理Lb


为什么要做这个

1，最开始是特殊需求，业务中需要知道  c端  ip地址 （知道源ip），这个如果放在http应用不是问题因为我们可以在http都不添加，但是由于我们业务比较变态，使用的是tcp长连接，并且业务要求服务器必须知道客户端源ip
正因为是这样，开源软件能解决这样的LB a,使用lvs dr模式 ，但是使用lvs 必须修改内核，pod内无法做这样的操作，因此放弃。b，使用haproxy 透明模式 ，何为透明模式 说白了 就是haproxy要充当pod的网关存在，这样才能解决包回来经过haproxy的目的，但是生产环境怎么能让haproxy做网关存在，这样在大并发大流量下ha必然是瓶颈，而且这样做网络也会非常负载，后来我想了个办法让需要对外提供服务，需要lb代理的pod  只有对外部访问使用haproxy做  下一跳网络，其他的默认网络都还使用原有的路由，这样就解决了 既能使用haproxy做透明代理，又不影响原有网络，这个是最初的设想 


2，a，先来介绍下，目前这套架构k8s 网络方面使用的是直连路由模式，通过静态路由打通所有网段，（也可以使用ospf来做），目前我这块的解决办法使用的是，依赖etcd3 服务注册开发出来的静态路由发现学习模式
b，lb使用多个haproxy 做前端代理 这层名为服务器发现层 使用多个haproxy 冗余提供同一业务负载代理能力（在这个前端可以针对haproxy在做lvs dr 或者使用等价路由方式做二层负载） 核心思想多个haproxy  代理后端多个pod（当业务量小的时候可以只使用1个），
c，haproxy端实现了自动注册，当haproxy掉线后 释放后端资源其他haproxy自动接管

3，网络上也有类似项目为什么不使用，或者说 k8s 默认提供的lb为什么不用

网络上最早玩的 是 confd 这个软件，我的很多思路也是参考这个软件的，非常感谢软件作者，为什么不用了 因为软件使用etcd2.0开发后续 etcd3.0 不支持了 、另外由于 软件兼容比较多，配置文件自定义无法做到很全面（具体来说是根据自己业务需求有的东西不好实现）、还有就是只能使用一个haproxy做代理无法扩展 当业务量大的使用就成为瓶颈



为什么不用k8s 默认提供的服务发现模式

不是说k8s默认提供的不好，而是就目前的业务逻辑来说，sdn虽然吵得很火，并且也很职能，但是对于我对sdn并不是很精通的人来说，还是传统网络放心点并且传统网络效率也高，至于复杂的sdn 就交给 底层去解决吧、又说到lb  k8s实现是通过iptable 来做的分发，理论上来讲 也不错，不过如果是我上文中说的  tcp 连接需要知道  源ip的业务来说 这个就有点问题了。



![Aaron Swartz](https://github.com/byebye758/kubernetes-haproxy-autolb/blob/master/doc/架构图.jpg）
532549992@qq.com  欢迎大家一起交流